{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting various ML models\n",
    "\n",
    "Basic preprocessing\n",
    "    - Remove stopwords from the text (custom wordlist?)\n",
    "    - Lemmatization?\n",
    "    \n",
    "Experiment with various feature engineering techniques\n",
    "    - Remove the aspect from the text\n",
    "    - CountVectorizer, TfidfVectorizer\n",
    "    - ngram ranges\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-04T07:53:20.722401Z",
     "start_time": "2020-07-04T07:53:18.531904Z"
    }
   },
   "outputs": [],
   "source": [
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy import load\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "nlp = load(\"en\")\n",
    "tokenizer = Tokenizer(nlp.vocab)\n",
    "\n",
    "\n",
    "# Remove Stopwords\n",
    "# Custom stopword list?\n",
    "def remove_stopwords(sentence) :\n",
    "    return \" \".join([str(token) for token in tokenizer(sentence.replace(',', '').replace(\".\",\"\").lower())\n",
    "                     if not token.is_stop and not token.is_punct and not token.is_digit and token.is_alpha])\n",
    "\n",
    "\n",
    "def lemmatize(sentence):\n",
    "    return \" \".join([token.lemma_ for token in nlp(sentencence)])\n",
    "\n",
    "def remove_aspect(text, aspect) :\n",
    "    pattern = '\\s*'+aspect.replace('(', '\\(').replace(')', '\\)')+'\\s*'\n",
    "    return re.sub(pattern, ' ', text)\n",
    "\n",
    "\n",
    "def split_text(text, on, method):\n",
    "    spltd = text.split(on)\n",
    "    \n",
    "    if method == 'before':\n",
    "        res = spltd[0]\n",
    "    elif method == 'after':\n",
    "        if len(spltd) > 1: \n",
    "            res = spltd[1]\n",
    "        else:\n",
    "            res = ' '\n",
    "    \n",
    "    return res\n",
    "\n",
    "# split and get left side of the sentence\n",
    "def split_left(text_splitpoint) :\n",
    "    sentence, split_point = text_splitpoint\n",
    "    return sentence.split(split_point)[0]\n",
    "\n",
    "\n",
    "# split and get right side of the sentence\n",
    "def split_right(text_splitpoint):\n",
    "    sentence, split_point = text_splitpoint\n",
    "    split = sentence.split(split_point)\n",
    "    return split[1] if len(split)>1 else \" \"\n",
    "\n",
    "\n",
    "def remove_polarity(polarity, df):\n",
    "    return df.loc[df.polarity != polarity, :]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-04T07:54:11.817345Z",
     "start_time": "2020-07-04T07:54:11.809254Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-04T07:54:12.099790Z",
     "start_time": "2020-07-04T07:54:12.077546Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils import load_raw_file\n",
    "df = load_raw_file('restaurants', 'train', '2014')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-04T07:54:12.472257Z",
     "start_time": "2020-07-04T07:54:12.455857Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>term</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>polarity</th>\n",
       "      <th>category</th>\n",
       "      <th>category_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3121</td>\n",
       "      <td>But the staff was so horrible to us.</td>\n",
       "      <td>staff</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>negative</td>\n",
       "      <td>service</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2777</td>\n",
       "      <td>To be completely fair, the only redeeming fact...</td>\n",
       "      <td>food</td>\n",
       "      <td>57</td>\n",
       "      <td>61</td>\n",
       "      <td>positive</td>\n",
       "      <td>food, anecdotes/miscellaneous</td>\n",
       "      <td>positive, negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1634</td>\n",
       "      <td>The food is uniformly exceptional, with a very...</td>\n",
       "      <td>food</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>positive</td>\n",
       "      <td>food</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1634</td>\n",
       "      <td>The food is uniformly exceptional, with a very...</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>55</td>\n",
       "      <td>62</td>\n",
       "      <td>positive</td>\n",
       "      <td>food</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1634</td>\n",
       "      <td>The food is uniformly exceptional, with a very...</td>\n",
       "      <td>menu</td>\n",
       "      <td>141</td>\n",
       "      <td>145</td>\n",
       "      <td>neutral</td>\n",
       "      <td>food</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                               text     term  from  \\\n",
       "0  3121               But the staff was so horrible to us.    staff     8   \n",
       "1  2777  To be completely fair, the only redeeming fact...     food    57   \n",
       "2  1634  The food is uniformly exceptional, with a very...     food     4   \n",
       "3  1634  The food is uniformly exceptional, with a very...  kitchen    55   \n",
       "4  1634  The food is uniformly exceptional, with a very...     menu   141   \n",
       "\n",
       "    to  polarity                       category   category_polarity  \n",
       "0   13  negative                        service            negative  \n",
       "1   61  positive  food, anecdotes/miscellaneous  positive, negative  \n",
       "2    8  positive                           food            positive  \n",
       "3   62  positive                           food            positive  \n",
       "4  145   neutral                           food            positive  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    cols = ['text', 'term', 'polarity']\n",
    "    df = remove_polarity('conflict', df).loc[:, cols]\n",
    "    \n",
    "   # remove stopwords\n",
    "    df.loc[:, 'text'] = df.text.apply(remove_stopwords)\n",
    "\n",
    "    # lemmatize\n",
    "    # texts = []\n",
    "    # for doc in nlp.pipe(df.text):\n",
    "    #     sent_lemmatized = ' '.join([token.lemma_ for token in doc])\n",
    "    #     texts.append(sent_lemmatized)\n",
    "\n",
    "    # df.loc[:, 'text'] = texts\n",
    "\n",
    "    # extract before aspect and after aspect sentence\n",
    "    df['before_aspect'] = df.loc[:, ['text', 'term']].apply(\n",
    "                          lambda r: split_text(r['text'], r['term'], 'before'), axis=1)\n",
    "\n",
    "    df['after_aspect'] = df.loc[:, ['text', 'term']].apply(\n",
    "                          lambda r: split_text(r['text'], r['term'], 'after'), axis=1)\n",
    "\n",
    "    # remove aspect \n",
    "    df['without_aspect'] = df.loc[:, ['text', 'term']].apply(\n",
    "                          lambda r: remove_aspect(r['text'], r['term']), axis=1)\n",
    "    \n",
    "    \n",
    "    return df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-04T07:54:15.847294Z",
     "start_time": "2020-07-04T07:54:15.823470Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>term</th>\n",
       "      <th>polarity</th>\n",
       "      <th>before_aspect</th>\n",
       "      <th>after_aspect</th>\n",
       "      <th>without_aspect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>staff horrible</td>\n",
       "      <td>staff</td>\n",
       "      <td>negative</td>\n",
       "      <td></td>\n",
       "      <td>horrible</td>\n",
       "      <td>horrible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>completely fair redeeming factor food average ...</td>\n",
       "      <td>food</td>\n",
       "      <td>positive</td>\n",
       "      <td>completely fair redeeming factor</td>\n",
       "      <td>average deficiencies teodora</td>\n",
       "      <td>completely fair redeeming factor average defic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>food uniformly exceptional capable kitchen pro...</td>\n",
       "      <td>food</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "      <td>uniformly exceptional capable kitchen proudly...</td>\n",
       "      <td>uniformly exceptional capable kitchen proudly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>food uniformly exceptional capable kitchen pro...</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>positive</td>\n",
       "      <td>food uniformly exceptional capable</td>\n",
       "      <td>proudly whip feel like eating menu</td>\n",
       "      <td>food uniformly exceptional capable proudly whi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>food uniformly exceptional capable kitchen pro...</td>\n",
       "      <td>menu</td>\n",
       "      <td>neutral</td>\n",
       "      <td>food uniformly exceptional capable kitchen pro...</td>\n",
       "      <td></td>\n",
       "      <td>food uniformly exceptional capable kitchen pro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     term  polarity  \\\n",
       "0                                     staff horrible    staff  negative   \n",
       "1  completely fair redeeming factor food average ...     food  positive   \n",
       "2  food uniformly exceptional capable kitchen pro...     food  positive   \n",
       "3  food uniformly exceptional capable kitchen pro...  kitchen  positive   \n",
       "4  food uniformly exceptional capable kitchen pro...     menu   neutral   \n",
       "\n",
       "                                       before_aspect  \\\n",
       "0                                                      \n",
       "1                  completely fair redeeming factor    \n",
       "2                                                      \n",
       "3                food uniformly exceptional capable    \n",
       "4  food uniformly exceptional capable kitchen pro...   \n",
       "\n",
       "                                        after_aspect  \\\n",
       "0                                           horrible   \n",
       "1                       average deficiencies teodora   \n",
       "2   uniformly exceptional capable kitchen proudly...   \n",
       "3                 proudly whip feel like eating menu   \n",
       "4                                                      \n",
       "\n",
       "                                      without_aspect  \n",
       "0                                           horrible  \n",
       "1  completely fair redeeming factor average defic...  \n",
       "2   uniformly exceptional capable kitchen proudly...  \n",
       "3  food uniformly exceptional capable proudly whi...  \n",
       "4  food uniformly exceptional capable kitchen pro...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-04T07:54:16.562275Z",
     "start_time": "2020-07-04T07:54:16.543645Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    2164\n",
       "negative     805\n",
       "neutral      633\n",
       "Name: polarity, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.polarity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-04T08:10:46.253245Z",
     "start_time": "2020-07-04T08:10:46.245132Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-04T08:09:28.451494Z",
     "start_time": "2020-07-04T08:09:28.448664Z"
    }
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-04T08:09:28.894392Z",
     "start_time": "2020-07-04T08:09:28.889203Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df.without_aspect\n",
    "y_train = le.fit_transform(df.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer()\n",
    "cvec.fit(X_train)\n",
    "\n",
    "X_train_lr = np.hstack([cvec.transform(df.before_aspect).A, cvec.transform(df.after_aspect).A])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-04T08:09:29.310142Z",
     "start_time": "2020-07-04T08:09:29.177688Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test = load_raw_file('restaurants', 'test')\n",
    "df_test = preprocess(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-04T08:09:29.310142Z",
     "start_time": "2020-07-04T08:09:29.177688Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test = df_test.without_aspect\n",
    "y_test = le.transform(df_test.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-04T08:09:29.310142Z",
     "start_time": "2020-07-04T08:09:29.177688Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test_lr = np.hstack([cvec.transform(df_test.before_aspect).A, cvec.transform(df_test.after_aspect).A])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-05T08:21:00.777561Z",
     "start_time": "2020-07-05T08:20:58.896790Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorize',\n",
       "                 TfidfVectorizer(max_features=6000, ngram_range=(1, 2))),\n",
       "                ('clf', SVC(C=1))])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('vectorize', TfidfVectorizer(max_features=6000, ngram_range=(1, 2),)),\n",
    "    ('clf', SVC(C=1))\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
