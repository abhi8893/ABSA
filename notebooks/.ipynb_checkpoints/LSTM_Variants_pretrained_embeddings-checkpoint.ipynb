{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing LSTM models for Aspect term polarity detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Paper Reference:** [Effective LSTMs for Target-Dependent Sentiment Classification](https://www.aclweb.org/anthology/C16-1311.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhi/miniconda3/envs/absa/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/abhi/miniconda3/envs/absa/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/abhi/miniconda3/envs/absa/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/abhi/miniconda3/envs/absa/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/abhi/miniconda3/envs/absa/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/abhi/miniconda3/envs/absa/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from dl_utils import prepare_data_for_dl\n",
    "from utils import f1\n",
    "import os\n",
    "\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the various global variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T11:50:49.453532Z",
     "start_time": "2020-07-24T11:50:49.447989Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_INPUT_LENGTH = 80\n",
    "MAX_ASPECT_LENGTH = 5\n",
    "EMBEDDING_DIM = 200\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the training and test data\n",
    "\n",
    "Various Experiments can be run using the function:\n",
    "\n",
    "1. In case of glOve choose the embed_dim as 50, 100, 200, 300d\n",
    "2. Choose the embedding type i.e. glove, google (300d), restaurants, laptops\n",
    "3. Choose a combination of embeddings i.e. double embeddings glove and restaurants\n",
    "4. Choose whether to concatenate POS tags or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word vectors found for 93.10% of vocabulary\n",
      "Word vectors found for 100.00% of vocabulary\n"
     ]
    }
   ],
   "source": [
    "train_data = prepare_data_for_dl('restaurants', 'train', embed_dim=EMBEDDING_DIM, \n",
    "                                 max_input_len=MAX_INPUT_LENGTH, max_aspect_len=MAX_ASPECT_LENGTH, \n",
    "                                 embed_type=['glove.twitter', 'restaurants'], concat_pos_tag=True)\n",
    "tokenizer = train_data['tokenizer']\n",
    "embedding_matrix = train_data['embedding_matrix']\n",
    "test_data = prepare_data_for_dl('restaurants', 'test', max_input_len=MAX_INPUT_LENGTH, \n",
    "                                max_aspect_len=MAX_ASPECT_LENGTH, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4728, 80)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['reviews_raw_idx'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_data['reviews_raw_idx'], train_data['polarity_ohe']\n",
    "X_test, y_test = test_data['reviews_raw_idx'], test_data['polarity_ohe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "postags_train = train_data['postags_raw']\n",
    "postags_test = test_data['postags_raw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Activation, LSTM, Embedding, GlobalMaxPool1D, Conv1D, Dropout\n",
    "from keras.utils import plot_model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../reports/Simple_LSTM.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# embedding_matrix = np.zeros(shape=(3755, 406))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Concatenate, Conv1D, Bidirectional, GlobalMaxPool1D, MaxPooling1D, Flatten\n",
    "from keras.layers import SpatialDropout1D, Average, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.regularizers import l2\n",
    "from keras.initializers import RandomUniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = RandomUniform(minval=-0.003, maxval=0.003)\n",
    "reg = l2(0.001)\n",
    "\n",
    "LSTM_PARAMS = {\n",
    "'units': 200,\n",
    "'activation': 'tanh',\n",
    "'recurrent_activation': 'sigmoid',\n",
    "'kernel_initializer': init,\n",
    "'recurrent_initializer': init,\n",
    "'bias_initializer': init,\n",
    "'kernel_regularizer': reg,\n",
    "'recurrent_regularizer': reg,\n",
    "'bias_regularizer': reg,\n",
    "'dropout': 0,\n",
    "'recurrent_dropout': 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 80, 306)           1343646   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 200)               405600    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 603       \n",
      "=================================================================\n",
      "Total params: 1,749,849\n",
      "Trainable params: 406,203\n",
      "Non-trainable params: 1,343,646\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# input layer\n",
    "inputs = Input(shape=(MAX_INPUT_LENGTH, ))\n",
    "\n",
    "# Embedding layer\n",
    "x = Embedding(input_dim=len(tokenizer.word_index) + 1,\n",
    "              output_dim=306,\n",
    "              input_length=80,\n",
    "              weights=[embedding_matrix],\n",
    "              mask_zero=True,\n",
    "              trainable=False)(inputs)\n",
    "\n",
    "\n",
    "# LSTM layer\n",
    "x = LSTM(**LSTM_PARAMS)(x)\n",
    "# x = Conv1D(256, 5, activation='relu')(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "# x = Conv1D(128, 5, activation='relu')(x)\n",
    "# x= GlobalMaxPool1D()(x)\n",
    "\n",
    "# Finally compute the probabilities\n",
    "preds = Dense(3, activation='softmax')(x)\n",
    "\n",
    "# Specify the input and the output\n",
    "model = Model(inputs, preds)\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=Adam(lr=0.01), metrics=['acc', f1])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file=\"SimpleLSTM.png\", show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=128, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target dependent LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../reports/Target_dep_LSTM.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [train_data['reviews_left_with_aspects_idx'], train_data['reviews_right_with_aspects_idx']]\n",
    "X_test = [test_data['reviews_left_with_aspects_idx'], test_data['reviews_right_with_aspects_idx']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 80)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 80)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 80, 300)      1126500     input_7[0][0]                    \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   (None, 200)          400800      embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   (None, 200)          400800      embedding_5[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 400)          0           lstm_4[0][0]                     \n",
      "                                                                 lstm_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 3)            1203        concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,929,303\n",
      "Trainable params: 802,803\n",
      "Non-trainable params: 1,126,500\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# We need two inputs, the left side and the right side of the aspect (including the aspect in both)\n",
    "\n",
    "left_input = Input(shape=(MAX_INPUT_LENGTH,))\n",
    "right_input = Input(shape=(MAX_INPUT_LENGTH,))\n",
    "\n",
    "\n",
    "# Embedding layer\n",
    "Embedding_Layer = Embedding(input_dim=len(tokenizer.word_index) + 1,\n",
    "              output_dim=300,\n",
    "              input_length=80,\n",
    "              mask_zero=False,\n",
    "              weights=[embedding_matrix],\n",
    "              trainable=False)\n",
    "\n",
    "# Obtain the vectors from the embedding layers for\n",
    "# the left and right sequences\n",
    "left_x = Embedding_Layer(left_input)\n",
    "right_x = Embedding_Layer(right_input)\n",
    "\n",
    "\n",
    "# left_x = SpatialDropout1D(0.2)(left_x)\n",
    "# right_x = SpatialDropout1D(0.2)(right_x)\n",
    "\n",
    "# Pass both through separate LSTMS\n",
    "left_x = LSTM(**LSTM_PARAMS)(left_x)\n",
    "right_x = LSTM(**LSTM_PARAMS, go_backwards=True)(right_x)\n",
    "\n",
    "# left_x = Conv1D(filters=256, kernel_size=5, activation='relu', padding='same')(left_x)\n",
    "# left_x = Dropout(0.55)(left_x)\n",
    "# left_x = Conv1D(filters=128, kernel_size=5, activation='relu')(left_x)\n",
    "# left_x = MaxPooling1D(2)(left_x)\n",
    "# # left_x = GlobalMaxPool1D()(left_x)\n",
    "# left_x = Flatten()(left_x)\n",
    "# # # left_x = LSTM(units=50)(left_x)\n",
    "\n",
    "# right_x = Conv1D(filters=256, kernel_size=5, activation='relu', padding='same')(right_x)\n",
    "# right_x = Dropout(0.55)(right_x)\n",
    "# right_x = Conv1D(filters=128, kernel_size=5, activation='relu')(right_x)\n",
    "# right_x = MaxPooling1D(2)(right_x)\n",
    "# # right_x = GlobalMaxPool1D()(right_x)\n",
    "# right_x = Flatten()(right_x)\n",
    "# right_x = LSTM(go_backwards=True, units=50)(right_x)\n",
    "\n",
    "\n",
    "\n",
    "# Concatenate the final hidden states\n",
    "\n",
    "# x = Average()([left_x, right_x])\n",
    "x = Concatenate()([left_x, right_x])\n",
    "\n",
    "# Finally compute the probabilities\n",
    "preds = Dense(3, activation='softmax')(x)\n",
    "\n",
    "# Specify the input and the output\n",
    "model = Model(inputs=[left_input, right_input], outputs=preds)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.01), metrics=['acc', f1])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file=\"TD-LSTM.png\", show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3608 samples, validate on 1120 samples\n",
      "Epoch 1/10\n",
      "3608/3608 [==============================] - 28s 8ms/step - loss: 1.2767 - acc: 0.6028 - f1: 0.5670 - val_loss: 0.9933 - val_acc: 0.7063 - val_f1: 0.6735\n",
      "Epoch 2/10\n",
      "3608/3608 [==============================] - 27s 8ms/step - loss: 0.9079 - acc: 0.6865 - f1: 0.6576 - val_loss: 0.8225 - val_acc: 0.7170 - val_f1: 0.7027\n",
      "Epoch 3/10\n",
      "3608/3608 [==============================] - 28s 8ms/step - loss: 0.7937 - acc: 0.7098 - f1: 0.6922 - val_loss: 0.7924 - val_acc: 0.7134 - val_f1: 0.6887\n",
      "Epoch 4/10\n",
      "3608/3608 [==============================] - 30s 8ms/step - loss: 0.7489 - acc: 0.7284 - f1: 0.7096 - val_loss: 0.8314 - val_acc: 0.7125 - val_f1: 0.6981\n",
      "Epoch 5/10\n",
      "3608/3608 [==============================] - 28s 8ms/step - loss: 0.7260 - acc: 0.7439 - f1: 0.7256 - val_loss: 0.7925 - val_acc: 0.7143 - val_f1: 0.6889\n",
      "Epoch 6/10\n",
      "3608/3608 [==============================] - 28s 8ms/step - loss: 0.7061 - acc: 0.7550 - f1: 0.7441 - val_loss: 0.8270 - val_acc: 0.7250 - val_f1: 0.7159\n",
      "Epoch 7/10\n",
      "3608/3608 [==============================] - 31s 8ms/step - loss: 0.6865 - acc: 0.7686 - f1: 0.7598 - val_loss: 0.8219 - val_acc: 0.7223 - val_f1: 0.7030\n",
      "Epoch 8/10\n",
      "3608/3608 [==============================] - 39s 11ms/step - loss: 0.6785 - acc: 0.7733 - f1: 0.7675 - val_loss: 0.8129 - val_acc: 0.7188 - val_f1: 0.7053\n",
      "Epoch 9/10\n",
      "3608/3608 [==============================] - 31s 8ms/step - loss: 0.6667 - acc: 0.7907 - f1: 0.7796 - val_loss: 0.8705 - val_acc: 0.6955 - val_f1: 0.6833\n",
      "Epoch 10/10\n",
      "3608/3608 [==============================] - 30s 8ms/step - loss: 0.6717 - acc: 0.7849 - f1: 0.7783 - val_loss: 0.8806 - val_acc: 0.7152 - val_f1: 0.7106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd9c97844e0>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test).argmax(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7517857142857143"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test.argmax(axis=1), y_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7517857142857143"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test.argmax(axis=1), y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.31      0.38       196\n",
      "           1       0.83      0.90      0.86       728\n",
      "           2       0.60      0.65      0.63       196\n",
      "\n",
      "    accuracy                           0.75      1120\n",
      "   macro avg       0.64      0.62      0.62      1120\n",
      "weighted avg       0.73      0.75      0.74      1120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test.argmax(axis=1), y_pred, ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
