{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing LSTM models for Aspect term polarity detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Paper Reference:** [Effective LSTMs for Target-Dependent Sentiment Classification](https://www.aclweb.org/anthology/C16-1311.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from dl_utils import prepare_data_for_dl\n",
    "from utils import f1\n",
    "import os\n",
    "\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the various global variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_INPUT_LENGTH = 70\n",
    "MAX_ASPECT_LENGTH = 5\n",
    "EMBEDDING_DIM = 50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 80\n",
    "MAX_ASPECT_LENGTH = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = prepare_data_for_dl('restaurants', 'train', embed_dim=EMBEDDING_DIM, \n",
    "                                 max_input_len=MAX_INPUT_LENGTH, max_aspect_len=MAX_ASPECT_LENGTH)\n",
    "tokenizer = train_data['tokenizer']\n",
    "embedding_matrix = train_data['embedding_matrix']\n",
    "test_data = prepare_data_for_dl('restaurants', 'test', max_input_len=70, max_aspect_len=5, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_data['reviews_raw_idx'], train_data['polarity_ohe']\n",
    "X_test, y_test = test_data['reviews_raw_idx'], test_data['polarity_ohe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Activation, LSTM, Embedding\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../reports/Simple_LSTM.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 70, 50)            188150    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 200)               200800    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 603       \n",
      "=================================================================\n",
      "Total params: 389,553\n",
      "Trainable params: 201,403\n",
      "Non-trainable params: 188,150\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# input layer\n",
    "inputs = Input(shape=(MAX_INPUT_LENGTH, ))\n",
    "\n",
    "# Embedding layer\n",
    "x = Embedding(input_dim=len(tokenizer.word_index) + 1,\n",
    "              output_dim=EMBEDDING_DIM,\n",
    "              input_length=MAX_INPUT_LENGTH,\n",
    "              weights=[embedding_matrix],\n",
    "              trainable=False)(inputs)\n",
    "\n",
    "\n",
    "# LSTM layer\n",
    "x = LSTM(units=200, dropout=0.3, recurrent_dropout=0.3)(x)\n",
    "\n",
    "# Finally compute the probabilities\n",
    "preds = Dense(3, activation='softmax')(x)\n",
    "\n",
    "# Specify the input and the output\n",
    "model = Model(inputs, preds)\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam', metrics=['acc', f1])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3608 samples, validate on 1120 samples\n",
      "Epoch 1/5\n",
      "3608/3608 [==============================] - 11s 3ms/step - loss: 0.9486 - acc: 0.5984 - f1: 0.5353 - val_loss: 0.9114 - val_acc: 0.6473 - val_f1: 0.4647\n",
      "Epoch 2/5\n",
      "3608/3608 [==============================] - 11s 3ms/step - loss: 0.9384 - acc: 0.5876 - f1: 0.5224 - val_loss: 0.8657 - val_acc: 0.6500 - val_f1: 0.6460\n",
      "Epoch 3/5\n",
      "3608/3608 [==============================] - 11s 3ms/step - loss: 0.9225 - acc: 0.6006 - f1: 0.5404 - val_loss: 0.9067 - val_acc: 0.6500 - val_f1: 0.6483\n",
      "Epoch 4/5\n",
      "3608/3608 [==============================] - 12s 3ms/step - loss: 0.9405 - acc: 0.5992 - f1: 0.5202 - val_loss: 0.9070 - val_acc: 0.6500 - val_f1: 0.6500\n",
      "Epoch 5/5\n",
      "3608/3608 [==============================] - 12s 3ms/step - loss: 0.9379 - acc: 0.6012 - f1: 0.5993 - val_loss: 0.9013 - val_acc: 0.6500 - val_f1: 0.6500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3d715df908>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target dependent LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../reports/Target_dep_LSTM.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [train_data['reviews_left_with_aspects_idx'], train_data['reviews_right_with_aspects_idx']]\n",
    "X_test = [test_data['reviews_left_with_aspects_idx'], test_data['reviews_right_with_aspects_idx']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_19 (InputLayer)           (None, 70)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_20 (InputLayer)           (None, 70)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_11 (Embedding)        (None, 70, 50)       188150      input_19[0][0]                   \n",
      "                                                                 input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_16 (LSTM)                  (None, 200)          200800      embedding_11[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_17 (LSTM)                  (None, 200)          200800      embedding_11[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 400)          0           lstm_16[0][0]                    \n",
      "                                                                 lstm_17[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 3)            1203        concatenate_6[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 590,953\n",
      "Trainable params: 402,803\n",
      "Non-trainable params: 188,150\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# We need two inputs, the left side and the right side of the aspect (including the aspect in both)\n",
    "\n",
    "left_input = Input(shape=(MAX_INPUT_LENGTH,))\n",
    "right_input = Input(shape=(MAX_INPUT_LENGTH,))\n",
    "\n",
    "\n",
    "# Embedding layer\n",
    "Embedding_Layer = Embedding(input_dim=len(tokenizer.word_index) + 1,\n",
    "              output_dim=EMBEDDING_DIM,\n",
    "              input_length=MAX_INPUT_LENGTH,\n",
    "              mask_zero=True,\n",
    "              weights=[embedding_matrix],\n",
    "              trainable=False)\n",
    "\n",
    "# Obtain the vectors from the embedding layers for\n",
    "# the left and right sequences\n",
    "left_x = Embedding_Layer(left_input)\n",
    "right_x = Embedding_Layer(right_input)\n",
    "\n",
    "# Pass both through separate LSTMS\n",
    "left_x = LSTM(units=200)(left_x)\n",
    "right_x = LSTM(go_backwards=True, units=200)(right_x)\n",
    "\n",
    "# Concatenate the final hidden states\n",
    "x = Concatenate()([left_x, right_x])\n",
    "\n",
    "# Finally compute the probabilities\n",
    "preds = Dense(3, activation='softmax')(x)\n",
    "\n",
    "# Specify the input and the output\n",
    "model = Model(inputs=[left_input, right_input], outputs=preds)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc', f1])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3608 samples, validate on 1120 samples\n",
      "Epoch 1/1\n",
      "3608/3608 [==============================] - 22s 6ms/step - loss: 0.8594 - acc: 0.6297 - f1: 0.5789 - val_loss: 0.7304 - val_acc: 0.7045 - val_f1: 0.6573\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3d414c98d0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
