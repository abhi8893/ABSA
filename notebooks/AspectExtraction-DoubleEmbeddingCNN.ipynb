{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/abhi/miniconda3/envs/absa/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/abhi/miniconda3/envs/absa/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/abhi/miniconda3/envs/absa/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/abhi/miniconda3/envs/absa/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/abhi/miniconda3/envs/absa/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/abhi/miniconda3/envs/absa/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from utils import f1\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table('../data/processed/SemEval2014/restaurants_train.tsv').drop('word_id', axis=1)\n",
    "df_test = pd.read_table('../data/processed/SemEval2014/restaurants_gold.tsv').drop('word_id', axis=1).iloc[:, 1:]\n",
    "df_comb = pd.concat([df, df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>upos</th>\n",
       "      <th>xpos</th>\n",
       "      <th>head</th>\n",
       "      <th>deprel</th>\n",
       "      <th>lemma_index</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>But</td>\n",
       "      <td>but</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>CC</td>\n",
       "      <td>6</td>\n",
       "      <td>cc</td>\n",
       "      <td>but_0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>3</td>\n",
       "      <td>det</td>\n",
       "      <td>the_1</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>staff</td>\n",
       "      <td>staff</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>6</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>staff_2</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>was</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VBD</td>\n",
       "      <td>6</td>\n",
       "      <td>cop</td>\n",
       "      <td>be_3</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>so</td>\n",
       "      <td>so</td>\n",
       "      <td>ADV</td>\n",
       "      <td>RB</td>\n",
       "      <td>6</td>\n",
       "      <td>advmod</td>\n",
       "      <td>so_4</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12747</th>\n",
       "      <td>799</td>\n",
       "      <td>when</td>\n",
       "      <td>when</td>\n",
       "      <td>ADV</td>\n",
       "      <td>WRB</td>\n",
       "      <td>26</td>\n",
       "      <td>mark</td>\n",
       "      <td>when_22</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12748</th>\n",
       "      <td>799</td>\n",
       "      <td>on</td>\n",
       "      <td>on</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>26</td>\n",
       "      <td>case</td>\n",
       "      <td>on_23</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12749</th>\n",
       "      <td>799</td>\n",
       "      <td>warm</td>\n",
       "      <td>warm</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>26</td>\n",
       "      <td>amod</td>\n",
       "      <td>warm_24</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12750</th>\n",
       "      <td>799</td>\n",
       "      <td>pitas</td>\n",
       "      <td>pita</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>21</td>\n",
       "      <td>obl</td>\n",
       "      <td>pita_25</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12751</th>\n",
       "      <td>799</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>21</td>\n",
       "      <td>punct</td>\n",
       "      <td>._26</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60278 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       review_id   word  lemma   upos xpos  head  deprel lemma_index label\n",
       "0              0    But    but  CCONJ   CC     6      cc       but_0     O\n",
       "1              0    the    the    DET   DT     3     det       the_1     O\n",
       "2              0  staff  staff   NOUN   NN     6   nsubj     staff_2     B\n",
       "3              0    was     be    AUX  VBD     6     cop        be_3     O\n",
       "4              0     so     so    ADV   RB     6  advmod        so_4     O\n",
       "...          ...    ...    ...    ...  ...   ...     ...         ...   ...\n",
       "12747        799   when   when    ADV  WRB    26    mark     when_22     O\n",
       "12748        799     on     on    ADP   IN    26    case       on_23     O\n",
       "12749        799   warm   warm    ADJ   JJ    26    amod     warm_24     B\n",
       "12750        799  pitas   pita   NOUN  NNS    21     obl     pita_25     I\n",
       "12751        799      .      .  PUNCT    .    21   punct        ._26     O\n",
       "\n",
       "[60278 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lookup_dicts(series):\n",
    "    uniq_tokens = series.unique()\n",
    "    n = len(uniq_tokens)\n",
    "    w2id = dict(zip(uniq_tokens, range(1, n+1)))\n",
    "    id2w = {i: w for i, w in w2id.items()}\n",
    "    \n",
    "    return w2id, id2w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_X(df, col, w2id=None, lower=False, subset='train'):\n",
    "    df = df.copy()\n",
    "    if lower:\n",
    "        df[col] = df[col].str.lower()\n",
    "        \n",
    "    \n",
    "    if w2id is None:\n",
    "        w2id, id2w = get_lookup_dicts(df[col])\n",
    "    \n",
    "    df['wid'] = df[col].map(lambda x: w2id.get(x, np.nan))\n",
    "    df = df.dropna(subset=['wid'], axis=0)\n",
    "    \n",
    "    token_seq = df.groupby('review_id').wid.apply(lambda x: list(x)).tolist()\n",
    "    X = pad_sequences(token_seq, maxlen=83, padding='post')\n",
    "    \n",
    "    if subset == 'train':\n",
    "    \n",
    "        return X, w2id, id2w\n",
    "    else:\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, w2id, id2w = create_X(df, 'word', lower=True)\n",
    "X_test = create_X(df_test, col='word', w2id=w2id, lower=True, subset='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_train, pos2id, id2pos = create_X(df, 'xpos')\n",
    "pos_test = create_X(df_test, col='xpos', w2id=pos2id,  subset='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {'B': 1, 'I': 2, 'O': 0}\n",
    "\n",
    "def one_hot(x):\n",
    "    arr = [0, 0, 0]\n",
    "    i = label2id.get(x, 0)\n",
    "    arr[i] = 1\n",
    "    return arr\n",
    "\n",
    "def create_y(df):\n",
    "    \n",
    "    df = df.copy()\n",
    "    df['y'] = df.label.apply(one_hot)\n",
    "\n",
    "    y = df.groupby('review_id').y.apply(lambda x: list(x)).tolist()\n",
    "    y = pad_sequences(y, maxlen=83, padding='post')\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = create_y(df_comb)\n",
    "y_test = create_y(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load word vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word vectors found for 91.21% of vocabulary\n",
      "4815 nan\n",
      "Word vectors found for 99.98% of vocabulary\n"
     ]
    }
   ],
   "source": [
    "from dl_utils import create_embedding_matrix\n",
    "\n",
    "general_embedding = create_embedding_matrix(w2id, embed_dim=200, embed_type='glove.twitter', \n",
    "                                            concat_pos_tag=False)\n",
    "domain_embedding = create_embedding_matrix(w2id, embed_type='restaurants', \n",
    "                                            concat_pos_tag=False)\n",
    "\n",
    "embedding_matrix = np.hstack([general_embedding, domain_embedding])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../reports/DoubleCNN.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, Conv1D, Dropout, Dense, Masking, Multiply, Concatenate\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = 5\n",
    "embedding_size = embedding_matrix.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sentence (InputLayer)           (None, 83)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 83, 300)      1562700     sentence[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 83, 128)      192128      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 83, 128)      192128      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 83, 256)      0           conv1d_1[0][0]                   \n",
      "                                                                 conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 83, 256)      0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 83, 256)      327936      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 83, 256)      327936      conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 83, 256)      327936      conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 83, 3)        771         conv1d_5[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,931,535\n",
      "Trainable params: 1,368,835\n",
      "Non-trainable params: 1,562,700\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sent = Input(shape=(83, ), name='sentence')\n",
    "# pos = Input(shape=(83, ), name='pos')\n",
    "\n",
    "\n",
    "# Embedding layer\n",
    "x = Embedding(input_dim=len(w2id) + 1,\n",
    "                              output_dim=embedding_size,\n",
    "                              input_length=83,\n",
    "                              weights=[embedding_matrix],\n",
    "                              mask_zero=False,\n",
    "                              trainable=False)(sent)\n",
    "\n",
    "# pos_emb = Embedding(input_dim=len(pos2id) + 1,\n",
    "#                               output_dim=20,\n",
    "#                               input_length=83,\n",
    "#                               mask_zero=False,\n",
    "#                               trainable=True)(pos)\n",
    "\n",
    "\n",
    "# x = Concatenate()([x, pos_emb])\n",
    "\n",
    "filter_sizes = [3,5]\n",
    "convs = []\n",
    "for filter_size in filter_sizes:\n",
    "    conv = Conv1D(filters=128, kernel_size= kernel_size, padding='same', activation='relu')(x)\n",
    "    convs.append(conv)\n",
    "    \n",
    "    \n",
    "merged = Concatenate(axis=-1)(convs)\n",
    "\n",
    "x = Dropout(0.55)(merged)\n",
    "x = Conv1D(filters = 256, kernel_size = kernel_size, padding='same', activation='relu')(x)\n",
    "x = Conv1D(filters = 256, kernel_size = kernel_size, padding='same')(x)\n",
    "x = Conv1D(filters = 256, kernel_size = kernel_size, padding='same')(x)\n",
    "\n",
    "\n",
    "# Finally compute the probabilities\n",
    "preds = Dense(3, activation='softmax')(x)\n",
    "\n",
    "# Specify the input and the output\n",
    "model = Model(sent, preds)\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=Adam(lr=0.0001), metrics=['acc', f1])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "from keras import backend as K\n",
    "K.clear_session()\n",
    "\n",
    "plot_model(model, to_file=\"DoubleCNN_keras.png\", show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3044/3044 [==============================] - 32s 11ms/step - loss: 0.1207 - acc: 0.9614 - f1: 0.7872\n",
      "Epoch 2/5\n",
      "3044/3044 [==============================] - 31s 10ms/step - loss: 0.0716 - acc: 0.9710 - f1: 0.8537\n",
      "Epoch 3/5\n",
      "3044/3044 [==============================] - 49s 16ms/step - loss: 0.0486 - acc: 0.9576 - f1: 0.8951\n",
      "Epoch 4/5\n",
      "3044/3044 [==============================] - 59s 19ms/step - loss: 0.0414 - acc: 0.9640 - f1: 0.9001\n",
      "Epoch 5/5\n",
      "3044/3044 [==============================] - 43s 14ms/step - loss: 0.0373 - acc: 0.9667 - f1: 0.9044\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1932276a90>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=128, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_3d_label(y):\n",
    "    return y.reshape((y.shape[0]*y.shape[1], y.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_padded(y_test_flat, y_pred_flat):\n",
    "    idx = np.where(y_test_flat.any(axis=1))[0]\n",
    "    \n",
    "    return y_test_flat[idx, :], y_pred_flat[idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_test, y_pred, print_report=True):\n",
    "    y_test_flat = flatten_3d_label(y_test)\n",
    "    y_pred_flat = flatten_3d_label(y_pred)\n",
    "    \n",
    "    y_test_eval, y_pred_eval = drop_padded(y_test_flat, y_pred_flat)\n",
    "    y_test_eval, y_pred_eval = y_test_eval.argmax(axis=1), y_pred_eval.argmax(axis=1)\n",
    "    \n",
    "    if print_report:\n",
    "        print(classification_report(y_test_eval, y_pred_eval, \n",
    "                            labels=[1, 2, 0],target_names=['B', 'I', 'O']))\n",
    "        \n",
    "    \n",
    "    return y_test_eval, y_pred_eval\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.75      0.87      0.81      1132\n",
      "           I       0.78      0.67      0.72       571\n",
      "           O       0.98      0.97      0.98     11049\n",
      "\n",
      "    accuracy                           0.95     12752\n",
      "   macro avg       0.84      0.83      0.83     12752\n",
      "weighted avg       0.95      0.95      0.95     12752\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 0, ..., 1, 2, 0]), array([0, 1, 0, ..., 0, 1, 0]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
